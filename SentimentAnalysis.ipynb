{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkVAP5VOMsgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "from keras import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.models import load_model\n",
        "from numpy import mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTG2iQvS3-zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initialisation\n",
        "vocabulary_size = 5000\n",
        "max_words = 500\n",
        "embedding_size=32\n",
        "batch_size = 64\n",
        "num_epochs = 5\n",
        "activation='sigmoid'\n",
        "loss='binary_crossentropy'\n",
        "optimizer='adam'\n",
        "metrics=['accuracy']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGwFoknUM2Zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the data\n",
        "(X_train, y_train),(X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
        "print(\"Training samples :\",len(X_train))\n",
        "print(\"Test samples :\",len(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDgWapkcNJT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert the id to word in reviews -- only for understanding\n",
        "word2id = imdb.get_word_index()\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "def getWords(indexList):\n",
        "  print([id2word.get(i, ' ') for i in indexList])\n",
        "#print('---review index---')\n",
        "#print(X_train[6])\n",
        "#print('---review words---')\n",
        "#print(getWords(X_train[6]))\n",
        "#print('---label---')\n",
        "#print(y_train[6])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1RkZWZiOKjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(\"Before padding \",len(X_train[0]))\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "#print(\"After padding \",len(X_train[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-VHEpJUOeAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define model\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(LSTM(units = 100))\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation=activation))\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfwtq3oCOrWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#specify the loss function, optimizer and evaluation metrics \n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOH8WDvZOyGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training set\n",
        "X_training, y_training = X_train[batch_size:], y_train[batch_size:]\n",
        "#validation set\n",
        "X_validation, y_validation = X_train[:batch_size], y_train[:batch_size]\n",
        "print(\"Training samples : \",len(X_training))\n",
        "print(\"Validation samples : \",len(X_validation))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdacCveJ8RqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training\n",
        "histories = model.fit(X_training, y_training, validation_data=(X_validation, y_validation), batch_size=batch_size, epochs=num_epochs)\n",
        "model.save('sentiment_analysis.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VL7V_WgO9IK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VQozPXnNjEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training accuracy',mean(histories.history['accuracy'])*100)\n",
        "print('Test accuracy:', scores[1]*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecd8jWav-mCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert words to index\n",
        "def get_word_index(review_words):\n",
        "  words = review_words.split()\n",
        "  review = []\n",
        "  for word in words:\n",
        "    if word not in word2id:\n",
        "      review.append(2)\n",
        "    else:\n",
        "      review.append(word2id[word]+3)\n",
        "  return review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDHj-0YZ_mrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#movie prediction\n",
        "def prediction(review):\n",
        "  prediction = model.predict(review)\n",
        "  if prediction[0][0] > 0.5:\n",
        "    print(\"positive\",prediction[0][0])\n",
        "  else:\n",
        "    print(\"negative\",prediction[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZowYEYuf7MGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_list = [\"This moview is bad\", \"This movie is good\", \"Did not understand the movie\",\"This movie is such a waste of time\",\"Movie is one time watch\"]\n",
        "for review in review_list:\n",
        "  print(\"Review : \",review)\n",
        "  review_index = get_word_index(review)\n",
        "  review_index = sequence.pad_sequences([review_index], maxlen=max_words)\n",
        "  prediction(review_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA8DVXfKHsTl",
        "colab_type": "text"
      },
      "source": [
        "Without droput \n",
        "\n",
        "Training accuracy 91.09454154968262\n",
        "Test accuracy: 86.76400184631348\n",
        "\n",
        "dropout 0.5, epochs - 5\n",
        "\n",
        "Training accuracy 86.3931655883789\n",
        "Test accuracy: 86.25199794769287\n",
        "\n",
        "dropout 0.2, epochs - 5\n",
        "\n",
        "Training accuracy 87.70052194595337\n",
        "Test accuracy: 87.26400136947632"
      ]
    }
  ]
}