{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkVAP5VOMsgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "from keras import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.models import load_model\n",
        "from numpy import mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTG2iQvS3-zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initialisation\n",
        "vocabulary_size = 5000\n",
        "max_words = 500\n",
        "embedding_size=32\n",
        "batch_size = 64\n",
        "num_epochs = 5\n",
        "activation='sigmoid'\n",
        "loss='binary_crossentropy'\n",
        "optimizer='adam'\n",
        "metrics=['accuracy']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGwFoknUM2Zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the data\n",
        "(X_train, y_train),(X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
        "print(\"Training samples :\",len(X_train))\n",
        "print(\"Test samples :\",len(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDgWapkcNJT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3cc30331-3ab5-4cd5-e643-6d9855d04901"
      },
      "source": [
        "#convert the id to word in reviews -- only for understanding\n",
        "word2id = imdb.get_word_index()\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "def getWords(indexList):\n",
        "  print([id2word.get(i, ' ') for i in indexList])\n",
        "#print('---review index---')\n",
        "#print(X_train[6])\n",
        "#print('---review words---')\n",
        "#print(getWords(X_train[6]))\n",
        "#print('---label---')\n",
        "#print(y_train[6])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1RkZWZiOKjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(\"Before padding \",len(X_train[0]))\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "#print(\"After padding \",len(X_train[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-VHEpJUOeAQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "4d717f87-f192-4948-949e-254050f0a9e7"
      },
      "source": [
        "#define model\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(LSTM(units = 100))\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(LSTM(100, dropout=0.5, recurrent_dropout=0.5))\n",
        "model.add(Dense(1, activation=activation))\n",
        "print(model.summary())"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfwtq3oCOrWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#specify the loss function, optimizer and evaluation metrics \n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOH8WDvZOyGe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3d4af6cb-42dc-4da5-e75d-712983eecf39"
      },
      "source": [
        "#training set\n",
        "X_training, y_training = X_train[batch_size:], y_train[batch_size:]\n",
        "#validation set\n",
        "X_validation, y_validation = X_train[:batch_size], y_train[:batch_size]\n",
        "print(\"Training samples : \",len(X_training))\n",
        "print(\"Validation samples : \",len(X_validation))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training samples :  24936\n",
            "Validation samples :  64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdacCveJ8RqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "1feb1c63-3155-4a6b-8b32-79ace2cf1a0a"
      },
      "source": [
        "#Training\n",
        "histories = model.fit(X_training, y_training, validation_data=(X_validation, y_validation), batch_size=batch_size, epochs=num_epochs)\n",
        "model.save('sentiment_analysis.h5')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 24936 samples, validate on 64 samples\n",
            "Epoch 1/5\n",
            "24936/24936 [==============================] - 245s 10ms/step - loss: 0.4566 - accuracy: 0.7821 - val_loss: 0.3930 - val_accuracy: 0.8594\n",
            "Epoch 2/5\n",
            "24936/24936 [==============================] - 251s 10ms/step - loss: 0.3162 - accuracy: 0.8754 - val_loss: 0.3967 - val_accuracy: 0.8438\n",
            "Epoch 3/5\n",
            "24936/24936 [==============================] - 254s 10ms/step - loss: 0.2638 - accuracy: 0.8980 - val_loss: 0.2277 - val_accuracy: 0.9531\n",
            "Epoch 4/5\n",
            "24936/24936 [==============================] - 252s 10ms/step - loss: 0.2210 - accuracy: 0.9145 - val_loss: 0.2365 - val_accuracy: 0.9062\n",
            "Epoch 5/5\n",
            "24936/24936 [==============================] - 248s 10ms/step - loss: 0.2218 - accuracy: 0.9149 - val_loss: 0.2403 - val_accuracy: 0.9062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VL7V_WgO9IK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VQozPXnNjEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training accuracy',mean(histories.history['accuracy'])*100)\n",
        "print('Test accuracy:', scores[1]*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA8DVXfKHsTl",
        "colab_type": "text"
      },
      "source": [
        "Without droput \n",
        "\n",
        "Training accuracy 91.09454154968262\n",
        "Test accuracy: 86.76400184631348\n",
        "\n",
        "dropout 0.5, epochs - 5\n",
        "\n",
        "Training accuracy 86.3931655883789\n",
        "Test accuracy: 86.25199794769287\n",
        "\n",
        "dropout 0.2, epochs - 5\n",
        "\n",
        "Training accuracy 87.70052194595337\n",
        "Test accuracy: 87.26400136947632"
      ]
    }
  ]
}